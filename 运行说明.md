# 运行完整数据爬虫的说明

## 准备工作

✅ Selenium已安装
✅ webdriver-manager已安装
✅ 脚本已配置完成

## 运行步骤

**在终端中运行以下命令：**

```bash
cd "/Users/huangchenxu/Desktop/US School/Parsons CDMPS/Data Visualization/Final  Project UFO/Scrape"
python3 scrape_all_paginated.py
```

## 运行过程

1. **首次运行**：webdriver-manager会自动下载匹配你Chrome版本的ChromeDriver
2. **浏览器打开**：会看到Chrome浏览器自动打开并访问NUFORC网站
3. **自动翻页**：脚本会自动检测总页数（1586页）并逐页爬取
4. **进度保存**：每10页自动保存一次到 `ufo_data_tiered_partial.csv`
5. **最终结果**：完成后生成 `ufo_data_tiered_full.csv`（包含所有15万条记录）

## 预计时间

- 总页数：1586页
- 每页处理时间：约2-5秒
- **总预计时间：1.5-2小时**

## 监控进度

运行过程中，你可以：
- 观察浏览器窗口，看到翻页过程
- 查看终端输出的进度信息
- 检查 `ufo_data_tiered_partial.csv` 文件（每10页更新一次）

## 中断和恢复

- **中断**：按 `Ctrl+C`，已获取的数据会自动保存
- **恢复**：如果中断，可以修改脚本从上次中断的页码继续（需要手动修改）

## 输出文件

- `ufo_data_tiered_partial.csv` - 中间保存文件（每10页更新）
- `ufo_data_tiered_full.csv` - 最终完整数据（包含所有15万条记录）

## 注意事项

- 确保网络连接稳定
- 不要关闭浏览器窗口
- 运行期间电脑不要休眠
- 可以最小化浏览器，但不要关闭

## 故障排查

如果遇到问题：

1. **ChromeDriver下载失败**：检查网络连接，或手动下载ChromeDriver
2. **浏览器无法打开**：确保已安装Chrome浏览器
3. **页面加载超时**：检查网络连接，可能需要重试

## 完成后

获取到完整数据后，可以运行图片爬虫：

```bash
python3 scrape_images_full.py
```

这会从 `ufo_data_tiered_full.csv` 读取数据，筛选Media=Y的记录，然后爬取图片。
